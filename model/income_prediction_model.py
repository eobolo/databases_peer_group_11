# -*- coding: utf-8 -*-
"""Income Prediction Model,.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VyEs8JRFivbosJ2cqBy8SLfMCihQRVrX
"""

import os
import joblib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Input,Activation,add,Concatenate ,Dropout
from tensorflow.keras.models import Sequential, Model
from keras import models
from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam
from tensorflow.keras.regularizers import l2,l1
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import recall_score, precision_score, f1_score,confusion_matrix, accuracy_score
from imblearn.over_sampling import ADASYN
from keras.models import load_model
from tensorflow.keras.models import save_model

df = pd.read_csv("/content/income_dataset.csv")
df.head(10)

df.dtypes

df.isnull().sum()

df = df.dropna()

numerical_df = df.select_dtypes(exclude=['object'])
numerical_df.columns

sns.heatmap(numerical_df.corr(), annot = True)

# Let's encode the categorical columns
l_encoder = LabelEncoder()

categorical_df = df.select_dtypes(include=['object'])
categorical_df = categorical_df.apply(l_encoder.fit_transform)
categorical_df.head(10)

df = df.drop(categorical_df.columns, axis=1)
df = pd.concat([df, categorical_df], axis=1)
df.head(10)

df['income_>50K'].value_counts()

plt.figure(figsize=(15,12))
sns.heatmap(df.corr(), annot=True, fmt='.3f', cmap='cividis')

X = df.drop('income_>50K', axis=1)
y = df['income_>50K']

X = df.drop('income_>50K', axis=1)
y = df['income_>50K']

# Apply ADASYN to generate synthetic samples
adasyn = ADASYN(random_state=42)
X_resampled, y_resampled = adasyn.fit_resample(X, y)

# Verify the new class distribution
print("Class distribution after ADASYN:")
print(pd.Series(y_resampled).value_counts())

# Split into training and temporary set (for validation and testing)
X_train, X_temp, y_train, y_temp = train_test_split(
    X_resampled, y_resampled, test_size=0.3, random_state=42
)

# Split the temporary set into validation and testing sets
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

def define_model(optimization: str, regularization_datatype, early_stopping: bool, dropout: float, learning_rate: float):
    model = Sequential()
    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer= optimization,
                 loss='binary_crossentropy',
                 metrics=['accuracy'])

    return model

def evaluate_model(model, X_test, y_test, model_name="Model", threshold=0.5):
    print(f"\nEvaluating {model_name}...\n")
    # Evaluate loss and accuracy
    _, test_acc = model.evaluate(X_test, y_test, verbose=0)
    # Predict probabilities
    y_pred = model.predict(X_test)
    # Apply the custom threshold
    y_pred_classes = (y_pred >= threshold).astype(int)
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred_classes)
    recall = recall_score(y_test, y_pred_classes)
    precision = precision_score(y_test, y_pred_classes)
    f1 = f1_score(y_test, y_pred_classes)
    cm = confusion_matrix(y_test, y_pred_classes)

    # Print metrics
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("Confusion Matrix:")
    print(cm)

    # Save the model
    model.save(f'{model_name}.keras')
    print(f"Model '{model_name}' saved successfully.")
    print("\nConfusion Matrix:\n", cm)

    # Visualize Confusion Matrix
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()

def loss_curve_plot(model, history,X_test, model_name="Model"):
    #  Plot Loss Curve
    epochs = range(1, len(history.history['loss']) + 1)
    plt.figure(figsize=(10, 5))
    plt.plot(epochs, history.history['loss'], 'bo-', label='Training Loss')
    plt.plot(epochs, history.history['val_loss'], 'r*-', label='Validation Loss')
    plt.title(f'{model_name} - Training & Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

model_1 = define_model('adam', None, False, 0.0, 0.0)
history_1 = model_1.fit(X_train, y_train,
                         batch_size=32,
                          validation_data=(X_val, y_val),
                          verbose=1,
                          epochs=20);

evaluate_model(model_1, X_test, y_test, model_name="Model 1")

loss_curve_plot(model_1, history_1, X_test, model_name="Model 1")

model_2 = define_model('RMSprop', l2, False, 0.5, 0.01)
history_2 = model_2.fit(X_train, y_train,
                         batch_size=32,
                          validation_data=(X_val, y_val),
                          verbose=1,
                          epochs=30);

evaluate_model(model_2, X_test, y_test, model_name="Model 2")

loss_curve_plot(model_2, history_2, X_test, model_name="Model 2")

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

model_3 = define_model('Nadam', l2(0.05), True, 0.05, 0.01)
history_3 = model_3.fit(X_train, y_train,
                         batch_size=32,
                          validation_data=(X_val, y_val),
                          callbacks=[early_stopping],
                          verbose=1,
                          epochs=50);

evaluate_model(model_3, X_test, y_test, model_name="Model 3")

loss_curve_plot(model_2, history_2, X_test, model_name="Model 2")